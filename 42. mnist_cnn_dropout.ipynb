{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"42_mnist_cnn_dropout.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"id":"Y85M9h211Xox","colab_type":"text"},"cell_type":"markdown","source":["# 42. MNIST CNN with Dropout\n","\n","<p style=\"text-align: right;\">\n","blackdew7@gmail.com<br>\n","Your name :\n","</p>\n","\n","#### 선행지식\n","1. TensorFlow 다루기 기초\n","2. 모델링을 한다는 것에 대한 이해.\n","3. Supervised Learning 중 Classification에 대한 기본 지식.\n","4. CNN에 대한 기본 구조와 개념\n","\n","#### 실습목표\n","1. CNN의 구조를 Graph로 그려낼 수 있다.\n","2. 그려낸 Graph를 텐서플로우를 이용해 코딩할 수 있다.\n","3. Dropout을 이해하고 사용할 수 있다.\n","\n","#### 사용데이터.\n","\n","01. Multinomial Classification : http://yann.lecun.com/exdb/mnist/"]},{"metadata":{"id":"YmrIGpW21Xo2","colab_type":"text"},"cell_type":"markdown","source":["## 00. 라이브러리 불러오기"]},{"metadata":{"id":"F1K1Mq4l1Xo4","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# MNIST and Convolutional Neural Network\n","import tensorflow as tf \n","import numpy as np\n","import random"],"execution_count":0,"outputs":[]},{"metadata":{"id":"VtVN_fie1XpG","colab_type":"text"},"cell_type":"markdown","source":["## 01. 데이터 불러오기 & 전처리"]},{"metadata":{"id":"dAt0acAX1XpI","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n","print(tf.convert_to_tensor(mnist.train.images).get_shape())"],"execution_count":0,"outputs":[]},{"metadata":{"id":"5p8unIan1XpT","colab_type":"text"},"cell_type":"markdown","source":["## 02. Prepare Variables for a CNN Graph with TF"]},{"metadata":{"id":"L_z8a3Bd1XpV","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Graph Clear\n","tf.reset_default_graph()\n","tf.set_random_seed(2017) # random seeding - reproduct\n","\n","############################\n","# Place Holders\n","\n","X = tf.placeholder(tf.float32, [None, 784])\n","X_img = tf.reshape(X, [-1, 28, 28, 1])\n","Y = tf.placeholder(tf.float32, [None, 10])\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Ep5X8KFr1Xpd","colab_type":"text"},"cell_type":"markdown","source":["## 03. Make a CNN Graph with TF"]},{"metadata":{"id":"2mZO0VS11Xpk","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# for Conv Layer 01 filter - shape=(3, 3, 1)\n","w1 = tf.Variable(tf.random_normal([3, 3, 1, 64], stddev=0.01))\n","b1 = tf.Variable(tf.random_normal([64], stddev=0.01))\n","conv1 = tf.nn.conv2d(X_img, w1, strides=[1, 1, 1, 1], padding='SAME')\n","conv1 = tf.add(conv1, b1)\n","conv1 = tf.nn.relu(conv1)\n","pool1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n","\n","# for Conv Layer 02 filter - shape=(3, 3, 32)\n","w2 = tf.Variable(tf.random_normal([3, 3, 64, 128], stddev=0.01))\n","b2 = tf.Variable(tf.random_normal([128], stddev=0.01))\n","conv2 = tf.nn.conv2d(pool1, w2, strides=[1, 1, 1, 1], padding='SAME')\n","conv2 = tf.add(conv2, b2)\n","conv2 = tf.nn.relu(conv2)\n","pool2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n","\n","# pool2 => (?, 7, 7, 128)\n","\n","# fully connected layer 1\n","flat = tf.reshape(pool2, [-1, 7 * 7 * 128])\n","wfc1 = tf.Variable(tf.random_normal([7 * 7 * 128, 128], stddev=0.01))\n","bfc1 = tf.Variable(tf.random_normal([128], stddev=0.01))\n","fc1 = tf.add(tf.matmul(flat, wfc1), bfc1)\n","fc1 = tf.nn.relu(fc1, name=\"L1_fc_relu\")\n","\n","# dropout\n","keep_prob = tf.placeholder(tf.float32)\n","fc_drop = tf.nn.dropout(fc1, keep_prob=keep_prob)\n","\n","# fully connected layer 2\n","wfc2 = tf.Variable(tf.random_normal([128, 10], stddev=0.01))\n","bfc2 = tf.Variable(tf.random_normal([10], stddev=0.01))\n","logits = tf.add(tf.matmul(fc_drop, wfc2), bfc2)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"DjvHw-Iu1XqU","colab_type":"text"},"cell_type":"markdown","source":["#### Dropout\n","\n","![image](https://2.bp.blogspot.com/-WXlVLu2mT4g/WGUcrNdmzcI/AAAAAAAALHA/LmUZbEsJHrw4EjpIkGDVgPzZte4rcM8bwCLcB/s1600/dropout.png)"]},{"metadata":{"id":"ku0_a7KY1Xqi","colab_type":"text"},"cell_type":"markdown","source":["###  Cost & Optimizer"]},{"metadata":{"id":"Mr2J27Hs1Xqj","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# learning_rate도 placeholder로 만들어보자.\n","learning_rate = tf.placeholder(tf.float32)\n","\n","# Cost(loss) function & Optimizer\n","cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=Y))\n","optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Z2LXsAo61Xql","colab_type":"text"},"cell_type":"markdown","source":["### 실습 - Make a CNN Graph with TF"]},{"metadata":{"id":"OQXVvxmh1Xqn","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["'''\n","CNN Graph 코드를 완성해보자\n","\n","여러분이 직접 스크립트를 짜야 합니다.\n","복사하여 붙여넣기를 하지 마시고, 직접 타이핑 하는 것을 권장합니다.\n","'''\n","\n","# Graph Clear\n","tf.reset_default_graph()\n","tf.set_random_seed(2017) # random seeding - reproduct\n","\n","############################\n","# Place Holders\n","\n","X = tf.placeholder(tf.float32, [None, 784])\n","X_img = tf.reshape(X, [-1, 28, 28, 1])\n","Y = tf.placeholder(tf.float32, [None, 10])\n","\n","kp = tf.placeholder(tf.float32)\n","lr = tf.placeholder(tf.float32)\n","\n","#########################\n","# ConvLayer 01 \n","\n","with tf.name_scope(\"layer1_conv\"):\n","\n","    # for Conv Layer 01 filter - shape=(3, 3, 1)\n","    W1 = \n","\n","    # Convolution Layer 01 -> (?, 28, 28, 32)\n","    conv1 = \n","    conv1 = \n","\n","    # Pooling Layer 01 -> (?, 14, 14, 32)\n","    pool1 = \n","\n","\n","#########################\n","# ConvLayer 02\n","\n","with tf.name_scope(\"layer2_conv\"):\n","\n","    # for Conv Layer 02 filter - shape=(3, 3, 32)\n","    W2 = \n","\n","    # Convolution Layer 02 -> (?, 14, 14, 32)\n","    conv2 = \n","    conv2 = \n","\n","    # Pooling Layer 02 -> (?, 7, 7, 64)\n","    pool2 = \n","\n","\n","#########################\n","# Fully Connected Layer 01\n","\n","with tf.name_scope(\"layer1_fc\"):\n","\n","    # Flatten layer\n","    flat = \n","\n","    # for Final FC 7x7x64 inputs -> 1000\n","    wfc1 = tf.Variable(tf.random_normal([7 * 7 * 64, 1000], stddev=0.01))\n","    bfc1 = tf.Variable(tf.random_normal([1000], stddev=0.01))\n","\n","    # for Final FC Layer 1: 7x7x64 inputs -> 1000\n","    fc1 = tf.add(tf.matmul(flat, wfc1), bfc1)\n","    fc1 = tf.nn.relu(fc1)\n","\n","    # Dropout\n","    fc_drop = tf.nn.dropout(fc1, keep_prob=kp)\n","\n","#########################\n","# Fully Connected Layer 02\n","\n","with tf.name_scope(\"layer2_fc\"):\n","\n","    # for Final FC 1000 inputs -> 10\n","    wfc2 = tf.Variable(tf.random_normal([1000, 10], stddev=0.01))\n","\n","    # bias\n","    bfc2 = tf.Variable(tf.random_normal([10]))\n","\n","    # for Final FC Layer 2: 1000 inputs -> 10\n","    logits = tf.add(tf.matmul(fc_drop, wfc2), bfc2)\n","\n","\n","#########################\n","# Cost & Optimizer\n","\n","with tf.name_scope(\"Optimizer\"):\n","    # Cost(loss) function & Optimizer\n","    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=Y), name=\"cost\")\n","    optimizer = tf.train.AdamOptimizer(learning_rate=lr).minimize(cost)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"prLfely71Xqp","colab_type":"text"},"cell_type":"markdown","source":["## 04. Traning & Evaluation"]},{"metadata":{"id":"NXA7IK_b1Xqq","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["'''\n","버그가 있습니다. 버그를 해결해 봅시다.\n","'''\n","\n","###########################\n","# Initialize\n","sess = tf.Session()\n","sess.run(tf.global_variables_initializer())\n","\n","###########################\n","# Training\n","\n","print('Learning started. It takes sometime.')\n","\n","\n","# 총 갯수: 55000개를 500개씩 (batch_size) 나누어 훈련 \n","#        => 110번 (n_of_batches) 훈련하게 된다. \n","epochs = 2\n","batch_size = 500\n","n_of_batches = int(mnist.train.num_examples / batch_size)\n","\n","for epoch in range(epochs):\n","    print(\"%dth epoch\" % (epoch + 1))\n","    \n","    for i in range(n_of_batches):\n","        X_batch, Y_batch = mnist.train.next_batch(batch_size)\n","        # 학습 진행\n","#         sess.run(optimizer, feed_dict={X: X_batch, Y: Y_batch})\n","        sess.run(optimizer, feed_dict={X: X_batch, Y: np.eye(10)[Y_batch], \n","                                       keep_prob: 0.7, learning_rate: 0.01})\n","        \n","        if ((i + 1) % 10 == 0):\n","            # 학습 상황 디스플레이\n","#             loss = sess.run(cost, feed_dict={X: X_batch, Y: Y_batch})\n","            loss = sess.run(cost, feed_dict={X: X_batch, Y: np.eye(10)[Y_batch], \n","                                             keep_prob: 1.0})\n","            print(\"%dth records, training cost: %.3f\" % (((i + 1) * batch_size), loss))\n","            \n","###########################\n","# Evaluation\n","\n","# Test model and check accuracy\n","correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n","acc = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n","# accuracy = sess.run(acc, feed_dict={X: mnist.test.images, Y: mnist.test.labels})\n","accuracy = sess.run(acc, feed_dict={X: mnist.test.images, Y: np.eye(10)[mnist.test.labels], \n","                                    keep_prob: 1.0})\n","\n","print('Accuracy: %.2f' % (accuracy * 100))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"TTleAE5xnaVR","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["\n","# Test model and check accuracy\n","correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n","acc = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n","# accuracy = sess.run(acc, feed_dict={X: mnist.test.images, Y: mnist.test.labels})\n","accuracy = sess.run(acc, feed_dict={X: mnist.test.images, Y: np.eye(10)[mnist.test.labels], \n","                                    keep_prob: 1.0, learning_rate: 0.01})\n","\n","print('Accuracy: %.2f' % (accuracy * 100))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"m5wu8QhQ1Xqs","colab_type":"text"},"cell_type":"markdown","source":["## 05. 실습 해답"]},{"metadata":{"id":"Mjgmj_oa1Xqu","colab_type":"text"},"cell_type":"markdown","source":["### 05.1 Import Library & Prepare MNIST Data"]},{"metadata":{"id":"XxJEcULW1Xqu","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","\n","mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n","print(tf.convert_to_tensor(mnist.train.images).get_shape())\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"RRiNjwOY1Xqz","colab_type":"text"},"cell_type":"markdown","source":["### 05.2 Prepare Variables for a CNN Graph with TF"]},{"metadata":{"id":"wJwbKAil1Xq0","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Graph Clear\n","tf.reset_default_graph()\n","tf.set_random_seed(2017) # random seeding - reproduct\n","\n","############################\n","# Place Holders\n","\n","X = tf.placeholder(tf.float32, [None, 784], name=\"X\")\n","X_img = tf.reshape(X, [-1, 28, 28, 1], name=\"X_img\")\n","Y = tf.placeholder(tf.float32, [None, 10], name=\"Y\")\n","\n","kp = tf.placeholder(tf.float32)\n","lr = tf.placeholder(tf.float32)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Z-XWV0cm1Xq4","colab_type":"text"},"cell_type":"markdown","source":["### 05.3 Make a CNN Graph & Run Session with TF"]},{"metadata":{"id":"SV0G_WjF1Xq6","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["\n","\n","#########################\n","# ConvLayer 01 \n","\n","with tf.name_scope(\"layer1_conv\"):\n","\n","    # for Conv Layer 01 filter - shape=(3, 3, 1)\n","    w1 = tf.Variable(tf.random_normal([3, 3, 1, 64], stddev=0.01))\n","    b1 = tf.Variable(tf.random_normal([64], stddev=0.01))\n","\n","    # Convolution Layer 01 -> (?, 28, 28, 32)\n","    conv1 = tf.nn.conv2d(X_img, w1, strides=[1, 1, 1, 1], padding='SAME')\n","    conv1 = tf.add(conv1, b1)\n","    conv1 = tf.nn.relu(conv1)\n","\n","    # Pooling Layer 01 -> (?, 14, 14, 32)\n","    pool1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n","\n","\n","#########################\n","# ConvLayer 02\n","\n","with tf.name_scope(\"layer2_conv\"):\n","\n","    # for Conv Layer 02 filter - shape=(3, 3, 32)\n","    w2 = tf.Variable(tf.random_normal([3, 3, 64, 128], stddev=0.01))\n","    b2 = tf.Variable(tf.random_normal([128], stddev=0.01))\n","\n","    # Convolution Layer 02 -> (?, 14, 14, 32)\n","    conv2 = tf.nn.conv2d(pool1, w2, strides=[1, 1, 1, 1], padding='SAME')\n","    conv2 = tf.add(conv2, b2)\n","    conv2 = tf.nn.relu(conv2)\n","\n","    # Pooling Layer 02 -> (?, 7, 7, 64)\n","    pool2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n","\n","\n","#########################\n","# Fully Connected Layer 01\n","\n","with tf.name_scope(\"layer1_fc\"):\n","\n","    ###############################\n","    # Flatten layer\n","    flat = tf.reshape(pool2, [-1, 7 * 7 * 128])\n","\n","    # for Final FC 7x7x64 inputs -> 1000\n","    wfc1 = tf.Variable(tf.random_normal([7 * 7 * 128, 1000], stddev=0.01))\n","    bfc1 = tf.Variable(tf.random_normal([1000], stddev=0.01))\n","\n","    # for Final FC Layer 1: 7x7x64 inputs -> 1000\n","    fc1 = tf.add(tf.matmul(flat, wfc1), bfc1)\n","    fc1 = tf.nn.relu(fc1)\n","\n","    #########################\n","    # Dropout\n","    fc_drop = tf.nn.dropout(fc1, keep_prob=kp)\n","    #########################\n","\n","\n","#########################\n","# Fully Connected Layer 02\n","\n","with tf.name_scope(\"layer2_fc\"):\n","\n","    # for Final FC 1000 inputs -> 10\n","    wfc2 = tf.Variable(tf.random_normal([1000, 10], stddev=0.01))\n","    bfc2 = tf.Variable(tf.random_normal([10]))\n","\n","    # for Final FC Layer 2: 1000 inputs -> 10\n","    logits = tf.add(tf.matmul(fc_drop, wfc2), bfc2)\n","\n","\n","#########################\n","# Cost & Optimizer\n","\n","with tf.name_scope(\"Optimizer\"):\n","    # Cost(loss) function & Optimizer\n","    cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=Y)\n","    cost = tf.reduce_mean(cross_entropy)\n","    optimizer = tf.train.AdamOptimizer(learning_rate=lr).minimize(cost)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"vPmn-oKM1Xq9","colab_type":"text"},"cell_type":"markdown","source":["### 05.4 Train & Evaluation"]},{"metadata":{"id":"xXsMdtM51Xq9","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["#########################\n","# Session initialize\n","\n","sess = tf.Session()\n","sess.run(tf.global_variables_initializer())\n","\n","###########################\n","# Traning\n","\n","print('Learning started. It takes sometime.')\n","\n","# 총 갯수: 55000개를 500개씩 (batch_size) 나누어 훈련 \n","#        => 110번 (n_of_batches) 훈련하게 된다. \n","epochs = 10\n","batch_size = 512\n","n_of_batches = int(mnist.train.num_examples / batch_size)\n","\n","for epoch in range(epochs):\n","    print(\"%dth epoch\" % (epoch + 1))\n","\n","    for i in range(n_of_batches):\n","        X_batch, Y_batch = mnist.train.next_batch(batch_size)\n","        # 학습 진행\n","        sess.run(optimizer, feed_dict={X: X_batch, Y: np.eye(10)[Y_batch], kp: 0.7, lr: 0.01})\n","        \n","        if ((i + 1) % 5 == 0):\n","            # 학습 상황 디스플레이\n","            loss = sess.run(cost, feed_dict={X: X_batch, Y: np.eye(10)[Y_batch], kp: 1.0, lr: 0.01})\n","            print(\"%dth records, training cost: %.3f\" % (((i + 1) * batch_size), loss))\n","            \n","print(\"Training Complete\")\n","\n","\n","###########################\n","# Evaluation\n","with tf.name_scope(\"Prediction\"):\n","    # Test model and check accuracy\n","    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n","    acc = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n","    accuracy = sess.run(acc, feed_dict={X: mnist.test.images, Y: np.eye(10)[mnist.test.labels], kp: 1.0, lr: 0.01})\n","    \n","print('Accuracy: %.2f' % (accuracy * 100))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"8eMD5ATZ1XrE","colab_type":"text"},"cell_type":"markdown","source":["### 성능을 한 번 확인해 보자. 제대로 되고 있는걸까?"]},{"metadata":{"id":"cq-o3_xb1XrE","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Get one and predict\n","r = random.randint(0, mnist.test.num_examples - 1)\n","print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n","print(\"Prediction: \", sess.run(tf.argmax(logits, 1), \n","                               feed_dict={X: mnist.test.images[r:r + 1],\n","                                         keep_prob: 1.0}))\n","\n","import matplotlib.pyplot as plt\n","plt.imshow(mnist.test.images[r:r + 1].reshape(28, 28), cmap='Greys', interpolation='nearest')\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"gWwrtVII1XrI","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# 세션을 종료하자\n","sess.close()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"G6nxovai1Xrq","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}