{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"44_mnist_cnn_ensemble.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"id":"ZHdQyKIfUYcV","colab_type":"text"},"cell_type":"markdown","source":["# 44. MNIST CNN with Ensemble\n","\n","<p style=\"text-align: right;\">\n","blackdew7@gmail.com<br>\n","Your name :\n","</p>\n","\n","#### 선행지식\n","1. TensorFlow 다루기 기초\n","2. 모델링을 한다는 것에 대한 이해.\n","3. Supervised Learning 중 Classification에 대한 기본 지식.\n","4. CNN에 대한 기본 구조와 개념\n","\n","#### 실습목표\n","1. CNN의 구조를 Graph로 그려낼 수 있다.\n","2. 그려낸 Graph를 텐서플로우를 이용해 코딩할 수 있다.\n","3. Dropout을 이해하고 사용할 수 있다.\n","4. Ensemble을 이해하고 사용할 수 있다.\n","5. CNN 레이어 구조를 Class로 구현할 수 있다.\n","\n","#### 사용데이터.\n","\n","01. Multinomial Classification : http://yann.lecun.com/exdb/mnist/"]},{"metadata":{"id":"JQrmtd5wUYcX","colab_type":"text"},"cell_type":"markdown","source":["## 00. 라이브러리 불러오기"]},{"metadata":{"id":"Z9q44VrsUYcY","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# 메모리 초기화\n","%reset"],"execution_count":0,"outputs":[]},{"metadata":{"id":"DoeC8qcYUYcc","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# MNIST and Convolutional Neural Network\n","import numpy as np\n","import tensorflow as tf\n","import random"],"execution_count":0,"outputs":[]},{"metadata":{"id":"PqjfQ_PTUYcf","colab_type":"text"},"cell_type":"markdown","source":["## 01. 데이터 불러오기 & 전처리"]},{"metadata":{"id":"JyeIYx-IUYcg","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["'''\n","tf.contrib.learn.datasets.load_dataset() 함수의 사용\n","'''\n","\n","mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n","print(mnist.train.images.shape)\n","\n","test_input, test_label = mnist.train.next_batch(500)\n","print(test_input.shape)\n","print(test_label.shape)\n","\n","# label이 (500,) -> (500, 10) 형태가 되어야 해서 단위행렬로 변환해 주는 과정이 필요하다.\n","print(np.eye(10)[test_label].shape)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"iDO_xJsZUYcu","colab_type":"text"},"cell_type":"markdown","source":["## 02. Class 만들기"]},{"metadata":{"id":"dL8uIRhFUYcv","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Graph Clear\n","tf.reset_default_graph()\n","\n","class ModelCNN:\n","    def __init__(self, sess, name):\n","        self.sess = sess\n","        self.name = name\n","        \n","        self.prepare()\n","        self.build_net()\n","        \n","    def prepare(self):\n","        self.X = tf.placeholder(tf.float32, [None, 28, 28, 1])\n","        self.Y = tf.placeholder(tf.float32, [None, 10])\n","        self.kp = tf.placeholder(tf.float32)\n","        self.lr = tf.placeholder(tf.float32)\n","    \n","    def build_net(self):        \n","        conv1 = self.conv(self.X, 1, 32)\n","        conv2 = self.conv(conv1, 32, 64)\n","        flat = tf.reshape(conv2, [-1, 7 * 7 * 64])\n","        fc = self.fc(flat, 7 * 7 * 64, 1000, activation=True, dropout=True)\n","        \n","        self.logits = self.fc(fc, 1000, 10, activation=False, dropout=False)\n","        self.cost = self.cost(self.logits, self.Y)\n","        self.accuracy = self.accuracy(self.logits, self.Y)\n","\n","        self.optimizer = self.optimizer(self.cost)\n","        \n","    def conv(self, x, in_cnt, out_cnt):\n","        # for Conv Layer filter - shape=(3, 3, 1)\n","        w = tf.Variable(tf.random_normal([3, 3, in_cnt, out_cnt], stddev=0.01))\n","        b = tf.Variable(tf.random_normal([out_cnt], stddev=0.01))\n","\n","        # Convolution Layer\n","        conv = tf.nn.conv2d(x, w, strides=[1, 1, 1, 1], padding='SAME')\n","        conv = tf.add(conv, b)\n","        conv = tf.nn.relu(conv)\n","\n","        # Pooling Layer\n","        pool = tf.nn.max_pool(conv, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n","        \n","        return pool\n","    \n","    def fc(self, x, in_cnt, out_cnt, activation=True, dropout=True):\n","        # for Final FC\n","        W = tf.Variable(tf.random_normal([in_cnt, out_cnt], stddev=0.01))\n","        b = tf.Variable(tf.random_normal([out_cnt], stddev=0.01))\n","\n","        # for Final FC\n","        fc = tf.add(tf.matmul(x, W), b)\n","        \n","        # activation\n","        if (activation):\n","            fc = tf.nn.relu(fc)\n","            \n","        # dropout\n","        if (dropout):\n","            fc = tf.nn.dropout(fc, keep_prob=self.kp)\n","        \n","        return fc\n","    \n","    def cost(self, logits, Y):\n","        cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=Y)\n","        cost = tf.reduce_mean(cross_entropy)\n","        return cost\n","    \n","    def optimizer(self, cost):\n","        optimizer = tf.train.AdamOptimizer(learning_rate=self.lr).minimize(cost)\n","        return optimizer\n","\n","    def accuracy(self, logits, Y):\n","        correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n","        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n","        return accuracy\n","\n","    def train(self, x_data, y_data, prob=0.7, lr=0.01):\n","        return self.sess.run(self.optimizer, feed_dict={self.X: x_data, self.Y: y_data, self.kp: prob, self.lr: lr})\n","\n","    def predict(self, x_test, prob=1.0, lr=0.01):\n","        return self.sess.run(self.logits, feed_dict={self.X: x_test, self.kp: prob, self.lr: lr})\n","\n","    def get_cost(self, x_data, y_data, prob=0.7, lr=0.01):\n","        return self.sess.run(self.cost, feed_dict={self.X: x_data, self.Y: y_data, self.kp: prob, self.lr: lr})\n","        \n","    def get_accuracy(self, x_test, y_test, prob=1.0, lr=0.01):\n","        return self.sess.run(self.accuracy, feed_dict={self.X: x_test, self.Y: y_test, self.kp: prob, self.lr: lr})"],"execution_count":0,"outputs":[]},{"metadata":{"id":"s9Gj8BqcUYcz","colab_type":"text"},"cell_type":"markdown","source":["## 04. Ensemble"]},{"metadata":{"id":"YeYMxqrvUYc1","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# initialize\n","sess = tf.Session()\n","\n","models = []\n","num_models = 5\n","for m in range(num_models):\n","    models.append(ModelCNN(sess, \"model\" + str(m)))\n","\n","sess.run(tf.global_variables_initializer())\n","\n","print('Learning Started!')\n","\n","epochs = 3\n","batch_size = 256\n","n_of_batches = int(mnist.train.num_examples / batch_size)\n","\n","# train each model\n","for m_idx, m in enumerate(models):\n","    print(\"%dth models\" % (m_idx + 1))\n","    \n","    for epoch in range(epochs):\n","        print(\"%dth epoch\" % (epoch + 1))\n","        \n","        for i in range(n_of_batches):\n","            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n","            m.train(batch_xs.reshape([-1, 28, 28, 1]), np.eye(10)[batch_ys])\n","\n","            # 학습 상황 디스플레이\n","            if ((i + 1) % 10 == 0):\n","                loss = m.get_cost(batch_xs.reshape([-1, 28, 28, 1]), np.eye(10)[batch_ys])\n","                print(\"%dth records, training cost: %.3f\" % (((i + 1) * batch_size), loss))\n","\n","        print('Accuracy:', m.get_accuracy(mnist.test.images.reshape([-1, 28, 28, 1]), np.eye(10)[mnist.test.labels]))\n","    \n","print('Learning Finished!')\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"2GFqQ6H6UYc6","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Test model and check accuracy\n","test_size = len(mnist.test.labels)\n","predictions = np.zeros([test_size, 10])\n","for m_idx, m in enumerate(models):\n","    print((m_idx + 1), 'Accuracy:', m.get_accuracy(mnist.test.images.reshape([-1, 28, 28, 1]), np.eye(10)[mnist.test.labels]))\n","    p = m.predict(mnist.test.images.reshape([-1, 28, 28, 1]))\n","    predictions += p\n","    \n","print(predictions)\n","print(tf.argmax(predictions, 1))\n","\n","# ensemble accuracy\n","ensemble_correct_prediction = tf.equal(tf.argmax(predictions, 1), mnist.test.labels)\n","ensemble_accuracy = tf.reduce_mean(tf.cast(ensemble_correct_prediction, tf.float32))\n","\n","print('Ensemble accuracy:', sess.run(ensemble_accuracy))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"uaPPs8WyUYc9","colab_type":"text"},"cell_type":"markdown","source":["### 성능을 한 번 확인해 보자. 제대로 되고 있는걸까?"]},{"metadata":{"id":"8OmAGu6xUYc_","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Get one and predict\n","r = random.randint(0, mnist.test.num_examples - 1)\n","predictions = np.zeros([1, 10])\n","for m_idx, m in enumerate(models):\n","    p = m.predict(mnist.test.images[r:r + 1].reshape([-1, 28, 28, 1]))\n","    predictions += p\n","    \n","print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n","print(\"Prediction: \", sess.run(tf.argmax(predictions, 1)))\n","\n","import matplotlib.pyplot as plt\n","plt.imshow(mnist.test.images[r:r + 1].reshape(28, 28), cmap='Greys', interpolation='nearest')\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ONl_ZQoSUYdE","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# 세션을 종료하자\n","sess.close()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"IOJDjhIIUYdI","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}