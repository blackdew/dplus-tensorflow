{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"54_convolutional_autoencoder.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"id":"rYqFLbNVAMIt","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from tensorflow.examples.tutorials.mnist import input_data\n","\n","mnist = input_data.read_data_sets(\"./MNIST_data/\", one_hot=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"hFAZ26jdAMI1","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Graph Clear\n","tf.reset_default_graph()\n","\n","# tf Graph Input\n","X = tf.placeholder(tf.float32, [None, 784], name='InputData')\n","X_img = tf.reshape(X, shape=[-1, 28, 28, 1])\n","Y = tf.placeholder(tf.float32, [None, 10], name='LabelData')\n","\n","###################\n","# encoder\n","\n","# conv layer\n","W1 = tf.Variable(tf.random_normal([5, 5, 1, 25], stddev=0.01))\n","b1 = tf.Variable(tf.random_normal([25], stddev=0.01))\n","h1 = tf.nn.conv2d(X_img, W1, strides=[1, 1, 1, 1], padding='SAME')\n","h1 = tf.nn.bias_add(h1, b1)\n","h1 = tf.nn.relu(h1)\n","\n","# pooling layer + dropout\n","p1 = tf.nn.max_pool(h1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n","do1 = tf.nn.dropout(p1, keep_prob=0.75)\n","\n","# fully connected layer\n","flat2 = tf.reshape(do1, shape=[-1, 14 * 14 * 25])\n","\n","# fc1\n","W2 = tf.Variable(tf.random_normal([14 * 14 * 25, 14 * 14 * 5], stddev=0.01))\n","b2 = tf.Variable(tf.random_normal([14 * 14 * 5], stddev=0.01))\n","fc2 = tf.nn.relu(tf.add(tf.matmul(flat2, W2), b2))\n","do2 = tf.nn.dropout(fc2, keep_prob=0.75)\n","\n","# fc2\n","W3 = tf.Variable(tf.random_normal([14 * 14 * 5, 14 * 14], stddev=0.01))\n","b3 = tf.Variable(tf.random_normal([14 * 14], stddev=0.01))\n","fc3 = tf.nn.relu(tf.add(tf.matmul(do2, W3), b3))\n","\n","###################\n","# decoder\n","\n","# fc2\n","W4 = tf.Variable(tf.random_normal([14 * 14, 14 * 14 * 5], stddev=0.01))\n","b4 = tf.Variable(tf.random_normal([14 * 14 * 5], stddev=0.01))\n","fc4 = tf.nn.relu(tf.add(tf.matmul(fc3, W4), b4))\n","do4 = tf.nn.dropout(fc4, keep_prob=0.75)\n","\n","# fc1\n","W5 = tf.Variable(tf.random_normal([14 * 14 * 5, 14 * 14 * 25], stddev=0.01))\n","b5 = tf.Variable(tf.random_normal([14 * 14 * 25], stddev=0.01))\n","fc5 = tf.nn.relu(tf.add(tf.matmul(do4, W5), b5))\n","do5 = tf.nn.dropout(fc5, keep_prob=0.75)\n","do5 = tf.reshape(do5, shape=[-1, 14, 14, 25])\n","\n","# deconv layer\n","dc1 = tf.contrib.layers.conv2d_transpose(do5, \n","                                         num_outputs=25, \n","                                         kernel_size=[5, 5],\n","                                         stride=[1, 1],\n","                                         padding='SAME',\n","                                         weights_initializer=tf.contrib.layers.xavier_initializer_conv2d(uniform=False),\n","                                         biases_initializer=tf.contrib.layers.xavier_initializer(uniform=False),\n","                                         activation_fn=tf.nn.relu)\n","\n","# up scaling\n","size = [int(dc1.shape[1] * 2), int(dc1.shape[2] * 2)]\n","up1 = tf.image.resize_bilinear(dc1, size=size, align_corners=None)\n","up1 = tf.reshape(up1, [-1, 28 * 28 * 25])\n","\n","W6 = tf.Variable(tf.random_normal([28 * 28 * 25, 28 * 28], stddev=0.01), dtype=tf.float32)\n","b6 = tf.Variable(tf.random_normal([28 * 28], stddev=0.01))\n","output = tf.nn.relu(tf.add(tf.matmul(up1, W6), b6))\n","\n","with tf.name_scope('cost'):\n","    cost = tf.reduce_mean(tf.pow(output - X, 2))\n","\n","with tf.name_scope('opt'):\n","    optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Ye87yFi0AMI5","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["n_epochs = 1\n","batch_size = 500\n","\n","sess = tf.Session()\n","sess.run(tf.global_variables_initializer())\n","\n","for epoch in range(n_epochs):\n","    n_batches = int(mnist.train.num_examples / batch_size)\n","\n","    # Loop over all batches\n","    for i in range(n_batches):\n","        batch_x, batch_y = mnist.train.next_batch(batch_size)\n","        sess.run(optimizer, feed_dict={X: batch_x})\n","\n","        if (i + 1) % 2 == 0:\n","            c = sess.run(cost, feed_dict={X: batch_x})\n","            print('Records: %d, cost: %.4f' % ((i + 1) * batch_size, c))\n","\n","    # Display logs per epoch step\n","    print('Epoch: %d / %d,  cost: %.4f' % (epoch + 1, n_epochs, c))\n","print('Optimization Finished')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"kHQs9el5AMI-","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Testing\n","# Encode and decode images from test set and visualize their reconstruction.\n","n = 4\n","canvas_orig = np.empty((28 * n, 28 * n))\n","canvas_recon = np.empty((28 * n, 28 * n))\n","for i in range(n):\n","    # MNIST test set\n","    batch_x, _ = mnist.test.next_batch(n)\n","    # Encode and decode the digit image\n","    g = sess.run(output, feed_dict={X: batch_x})\n","    \n","    # Display original images\n","    for j in range(n):\n","        # Draw the generated digits\n","        canvas_orig[i * 28:(i + 1) * 28, j * 28:(j + 1) * 28] = batch_x[j].reshape([28, 28])\n","    # Display reconstructed images\n","    for j in range(n):\n","        # Draw the generated digits\n","        canvas_recon[i * 28:(i + 1) * 28, j * 28:(j + 1) * 28] = g[j].reshape([28, 28])\n","\n","print(\"Original Images\")     \n","plt.figure(figsize=(n, n))\n","plt.imshow(canvas_orig, origin=\"upper\", cmap=\"gray\")\n","plt.show()\n","\n","print(\"Reconstructed Images\")\n","plt.figure(figsize=(n, n))\n","plt.imshow(canvas_recon, origin=\"upper\", cmap=\"gray\")\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"RvTmhQAiAMJC","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["%matplotlib inline\n","import matplotlib.pyplot as plt\n","import math\n","import numpy as np\n","\n","def plot_conv_weights(weights, input_channel=0):\n","    \n","    with tf.Session() as sess:\n","        sess.run(tf.global_variables_initializer())\n","\n","        w = sess.run(weights)\n","\n","        w_min = np.min(w)\n","        w_max = np.max(w)\n","\n","        num_filters = w.shape[3]\n","        num_grids = math.ceil(math.sqrt(num_filters))\n","        fig, axes = plt.subplots(num_grids, num_grids)\n","\n","        for i, ax in enumerate(axes.flat):\n","            if i < num_filters:\n","                img = w[:, :, input_channel, i]\n","                ax.imshow(img, vmin=w_min, vmax=w_max, interpolation='nearest', cmap='seismic')\n","\n","            ax.set_xticks([])\n","            ax.set_yticks([])\n","\n","        plt.show()\n","        \n","def plot_conv_layer(layer, image):\n","\n","    with tf.Session() as sess:\n","\n","        sess.run(tf.global_variables_initializer())\n","\n","        feed_dict = {X: [image]}\n","        values = sess.run(layer, feed_dict=feed_dict)\n","\n","        num_filters = values.shape[3]\n","        num_grids = math.ceil(math.sqrt(num_filters))\n","        fig, axes = plt.subplots(num_grids, num_grids)\n","\n","        for i, ax in enumerate(axes.flat):\n","            if i < num_filters:\n","                img = values[0, :, :, i]\n","                ax.imshow(img, interpolation='nearest', cmap='binary')\n","                \n","            ax.set_xticks([])\n","            ax.set_yticks([])\n","\n","        plt.show()"],"execution_count":0,"outputs":[]}]}