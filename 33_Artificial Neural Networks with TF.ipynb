{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "324c3256-4054-4685-a71c-ae0fe87670c2"
    }
   },
   "source": [
    "# 03. Artificial Neural Networks with TF\n",
    "\n",
    "<p style=\"text-align: right;\">\n",
    "rayleigh@dplus.company<br>\n",
    "blackdew7@gmail.com<br>\n",
    "Your name :\n",
    "</p>\n",
    "\n",
    "### Intro to TensorFlow 의 마지막 시간!<br>\n",
    "\n",
    "이 실습자료까지 학습하고나면, 모두 끝납니다!\n",
    "\n",
    "#### 선행지식\n",
    "1. 모델링을 한다는 것에 대한 이해.\n",
    "2. Logistic Regression, Linear Regression\n",
    "3. Activation function 과 레이어\n",
    "\n",
    "#### 실습목표\n",
    "1. ANN 의 구조를 Graph로 그려낼 수 있다.\n",
    "2. 그려낸 Graph를 텐서플로우를 이용해 코딩할 수 있다.\n",
    "3. ANN의 마지막 레이어에 따라서 Regression도 Classification도 가능함을 알고 코딩할 수 있다.\n",
    "\n",
    "#### 사용데이터.\n",
    "\n",
    "01. Multivariate Regression : http://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset\n",
    "02. Multinomial Classification : http://yann.lecun.com/exdb/mnist/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression with Artificial Neural Network\n",
    "\n",
    "실습 01의 Bike-Sharing Data를 기억하지요?\n",
    "\n",
    "단순히 Linear Regression을 사용하기에는 이런 저런 고민들이 됩니다.\n",
    "\n",
    "1. 변수가 저렇게 많으면 어차피 직관적인 해석은 안된다.\n",
    "2. 저 중 컨트롤 가능한 변수는 없었다.\n",
    "3. 어쨌든 인풋 데이터에 따라 아웃풋 데이터가 잘 나오면 된다.\n",
    "\n",
    "바야흐로, Artificial Neural Network가 필요한 때입니다.\n",
    "\n",
    "### Warm up before deep playing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "77420740-c7d1-42dc-8cbf-f131e6ac7001"
    }
   },
   "source": [
    "### 00. 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "41a29509-236f-4951-a9d2-6c2cf4963c6b"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "\n",
    "# 현재 작업 디렉토리 확인\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01. 저번에 했었던 모든 전처리들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "data_path = './Bike-Sharing-Dataset/hour.csv'\n",
    "rides = pd.read_csv(data_path)\n",
    "\n",
    "# 더미\n",
    "dummy_fields = ['season', 'weathersit', 'mnth', 'hr', 'weekday']\n",
    "for each in dummy_fields:\n",
    "    dummies = pd.get_dummies(rides[each], prefix=each, drop_first=False)\n",
    "    rides = pd.concat([rides, dummies], axis=1)\n",
    "\n",
    "# 드롭\n",
    "fields_to_drop = ['instant', 'dteday', 'season', 'weathersit', 'mnth', 'hr', 'weekday']\n",
    "data = rides.drop(fields_to_drop, axis=1)\n",
    "\n",
    "# 노말리이제이션(Scailing)\n",
    "quant_features = ['casual', 'registered', 'cnt', 'temp', 'atemp', 'hum', 'windspeed']\n",
    "# Store scalings in a dictionary so we can convert back later\n",
    "scaled_features = {}\n",
    "for each in quant_features:\n",
    "    mean, std = data[each].mean(), data[each].std()\n",
    "    scaled_features[each] = [mean, std]\n",
    "    data.loc[:, each] = (data[each] - mean) / std\n",
    "    \n",
    "# 트레이닝 / 테스트 셋\n",
    "test_data, train_data = data[-60*24:], data[:-60*24]\n",
    "\n",
    "target_fields = ['cnt', 'casual', 'registered']\n",
    "test_features, test_targets = test_data.drop(target_fields, axis=1), test_data[target_fields]\n",
    "train_features, train_targets = train_data.drop(target_fields, axis=1), train_data[target_fields]\n",
    "\n",
    "test_X, test_Y = test_features.values, test_targets.values\n",
    "train_X, train_Y = train_features.values, train_targets.values\n",
    "\n",
    "print(train_X.shape, train_Y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02. 손으로 그려보자 ANN\n",
    "\n",
    "일단은 같이 해봅시다!<br>\n",
    "맨 마지막에, 아무것도 안주고 여러분이 해야만 하는 부분이 있습니다!\n",
    "\n",
    "#### 조건 :\n",
    "* Hidden Layer는 3개만 쓰자.\n",
    "* Hidden Layer의 노드 수는 16, 8, 4 개로 한다.\n",
    "* Shape를 실수하지 말자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 03. Make a Graph with TF\n",
    "\n",
    "01.Linear Regression with TF 의 코드와 직접 비교해보셔도 좋습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "print(train_X.shape, train_Y.shape)\n",
    "(15435, 58),   (15435, 3)\n",
    "'''\n",
    "# Graph Clear & Make your Graph reproducible\n",
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(2017)\n",
    "\n",
    "# Hyper-Parameters & Option\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Input Layer, Real Y\n",
    "X = tf.placeholder(dtype=tf.float32, shape=[None, 58], name=\"X\")\n",
    "Y = tf.placeholder(dtype=tf.float32, shape=[None, 3], name=\"Y\")\n",
    "\n",
    "# 1st Hidden Layer\n",
    "W1 = tf.Variable(tf.random_normal([58, 16]), name='weight_1')\n",
    "b1 = tf.Variable(tf.random_normal([16]), name='bias_1')\n",
    "sum1 = tf.add(tf.matmul(X, W1), b1)\n",
    "hidden_output1 = tf.nn.relu(sum1)\n",
    "\n",
    "# 2nd Hidden Layer\n",
    "W2 = tf.Variable(tf.random_normal([16, 8]), name='weight_2')\n",
    "b2 = tf.Variable(tf.random_normal([8]), name='bias_2')\n",
    "sum2 = tf.add(tf.matmul(hidden_output1, W2), b2)\n",
    "hidden_output2 = tf.nn.relu(sum2)\n",
    "\n",
    "# last Hidden Layer\n",
    "W3 = tf.Variable(tf.random_normal([8, 8]), name='weight_3')\n",
    "b3 = tf.Variable(tf.random_normal([8]), name = 'bias_3')\n",
    "sum3 = tf.add(tf.matmul(hidden_output2, W3), b3)\n",
    "hidden_output3 = tf.nn.relu(sum3)\n",
    "\n",
    "# Output Layer\n",
    "Wo = tf.Variable(tf.random_normal([8, 3]), name='weight_o')\n",
    "bo = tf.Variable(tf.random_normal([3]), name='bias_o')\n",
    "Y_pred = tf.add(tf.matmul(hidden_output3, Wo), bo, name='Y_predicted')\n",
    "\n",
    "# Cost(loss) function & Optimizer\n",
    "cost = tf.losses.mean_squared_error(Y, Y_pred)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 04. Train! Session!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "start = time.clock()\n",
    "for i in range(5000):\n",
    "    # 학습 진행\n",
    "    sess.run(optimizer, feed_dict={X: train_X, Y: train_Y})\n",
    "    \n",
    "    if (i % 100 == 0):\n",
    "        # 학습 상황 디스플레이\n",
    "        tr_l = sess.run(cost, feed_dict={X: train_X, Y: train_Y})\n",
    "        print(\"{}th training---- training loss: {:.5f}\".format(i, tr_l))\n",
    "        \n",
    "print(\"Training Complete\")\n",
    "end = time.clock()\n",
    "\n",
    "print(\"Total elapsed time: {}\".format(end - start))\n",
    "print(\"Test loss: {:.5f}\".format(sess.run(cost, feed_dict={X: test_X, Y: test_Y})))\n",
    "\n",
    "Y_predicted = sess.run(Y_pred, feed_dict={X: test_X, Y: test_Y})\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# target_fields = ['cnt', 'casual', 'registered']\n",
    "column = 'registered'\n",
    "cindex = target_fields.index(column)\n",
    "rows0, rows1 = 1000, 1100\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "# 예측값도 Scaling 되어 있으므로 그것을 원래대로 되돌려주는 과정\n",
    "mean, std = scaled_features[column]\n",
    "predictions = Y_predicted[rows0:rows1, cindex] * std + mean\n",
    "REAL = test_Y[rows0:rows1, cindex] * std + mean\n",
    "\n",
    "#ax.plot(Y_predicted, label = 'Prediction')\n",
    "#ax.plot(test_Y, label = 'Real')\n",
    "ax.plot(predictions, label='Prediction')\n",
    "ax.plot(REAL, label='Real')\n",
    "ax.set_xlim(right=len(Y_predicted[rows0:rows1, cindex]))\n",
    "ax.legend()\n",
    "\n",
    "dates = pd.to_datetime(rides.iloc[test_data[rows0:rows1].index]['dteday'])\n",
    "dates = dates.apply(lambda d: d.strftime('%b %d'))\n",
    "ax.set_xticks(np.arange(len(dates))[12::24])\n",
    "_ = ax.set_xticklabels(dates[12::24], rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with Artificial Neural Network\n",
    "\n",
    "실습 02의 MNIST Data를 기억하지요?\n",
    "\n",
    "1. 변수가 저렇게 많으면 어차피 직관적인 해석은 안된다.\n",
    "2. 저 중 컨트롤 가능한 변수는 없었다.\n",
    "3. 어쨌든 인풋 데이터에 따라 아웃풋 데이터가 잘 나오면 된다.\n",
    "4. 원리가 어쨌든 정확성이 높아야 한다.\n",
    "\n",
    "\n",
    "### 외칩시다. NEURAL NETWORK!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "77420740-c7d1-42dc-8cbf-f131e6ac7001"
    }
   },
   "source": [
    "### 00. 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01. 저번에 했었던 모든 전처리들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = input_data.read_data_sets(\"./MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist.test.labels.tolist()[0].index(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "mnist 시각화 함수\n",
    "'''\n",
    "def mnist_plot(i):\n",
    "    pixels = mnist.test.images[i].reshape((28, 28))\n",
    "    a = mnist.test.labels.tolist()\n",
    "    plt.title('Label : {}'.format(a[i].index(1)))\n",
    "    plt.imshow(pixels, cmap='gray')\n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "0 ~ 9999 사이의 숫자를 넣어서 확인해보자.\n",
    "'''\n",
    "mnist_plot(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "트레이닝 데이터로 활용할 55000개 이미지, 테스트용 10000개 이미지\n",
    "28*28 사이즈의 이미지가 그냥 주욱 784칸 짜리 어레이에 담겨있다.\n",
    "레이블은 이미 one-hot encoding이 되어 있다.\n",
    "'''\n",
    "print(mnist.train.images.shape, mnist.train.labels.shape)\n",
    "print(mnist.test.images.shape, mnist.test.labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnist.train.labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02. 손으로 그려보자 ANN\n",
    "\n",
    "일단은 같이 해봅시다!<br>\n",
    "맨 마지막에, 아무것도 안주고 여러분이 해야만 하는 부분이 있습니다!\n",
    "\n",
    "#### 조건 :\n",
    "* Hidden Layer는 4개만 쓰자.\n",
    "* Hidden Layer의 노드 수는 256, 128, 64, 64 개로 한다.\n",
    "* Shape를 실수하지 말자.\n",
    "* 인풋의 Shape = [ None, 28\\*28 ], 아웃풋의 Shape = [ None, 10 ] 기억하자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 03. Make a Graph with TF\n",
    "\n",
    "02.Logistic Regression with TF 의 코드와 직접 비교해보셔도 좋습니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02. 텐서서플로우로 그래프를 만들자!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Graph Clear & Make your Graph reproducible\n",
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(2017)\n",
    "\n",
    "# Hyper-Parameters & Option\n",
    "learning_rate = 0.01\n",
    "training_epochs = 20\n",
    "batch_size = 128\n",
    "\n",
    "# Input Layer, Real Y\n",
    "X = tf.placeholder(dtype=tf.float32, shape=[None, 784])\n",
    "Y = tf.placeholder(dtype=tf.float32, shape=[None, 10])\n",
    "\n",
    "# 1st Hidden Layer\n",
    "W1 = tf.Variable(tf.random_normal([28 * 28, 512]), name='weight_1')\n",
    "b1 = tf.Variable(tf.random_normal([512]), name='bias_1')\n",
    "sum1 = tf.add(tf.matmul(X, W1), b1)\n",
    "hidden_output1 = tf.nn.relu(sum1)\n",
    "\n",
    "# 2nd Hidden Layer\n",
    "W2 = tf.Variable(tf.random_normal([512, 512]))\n",
    "b2 = tf.Variable(tf.random_normal([512]))\n",
    "sum2 = tf.add(tf.matmul(hidden_output1, W2), b2)\n",
    "hidden_output2 = tf.nn.relu(sum2)\n",
    "\n",
    "# 3rd Hidden Layer\n",
    "W3 = tf.Variable(tf.random_normal([512, 256]))\n",
    "b3 = tf.Variable(tf.random_normal([256]))\n",
    "sum3 = tf.add(tf.matmul(hidden_output2, W3), b3)\n",
    "hidden_output3 = tf.nn.relu(sum3)\n",
    "\n",
    "# 4nd Hidden Layer\n",
    "W4 = tf.Variable(tf.random_normal([256, 256]))\n",
    "b4 = tf.Variable(tf.random_normal([256]))\n",
    "sum4 = tf.add(tf.matmul(hidden_output3, W4), b4)\n",
    "hidden_output4 = tf.nn.relu(sum4)\n",
    "\n",
    "# Output Layer\n",
    "Wo = tf.Variable(tf.random_normal([256, 10]), name='weight_o')\n",
    "bo = tf.Variable(tf.random_normal([10]), name='bias_o')\n",
    "logits = tf.add(tf.matmul(hidden_output4, Wo), bo, name='logit')\n",
    "Y_prob = tf.nn.softmax(logits, name='Y_distribution')\n",
    "\n",
    "# Classification & Accuracy\n",
    "n_of_correct = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1), \n",
    "                        name='Comparison')\n",
    "accuracy = tf.reduce_mean(tf.cast(n_of_correct, tf.float32), \n",
    "                          name='accuracy')\n",
    "\n",
    "# Cost(loss) function & Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "784 * 512 + 512 * 512 + 512 * 256 + 256 * 256 + 256 * 10\n",
    "\n",
    "28 * 28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 03. 세션을 만들고, 학습시키자!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "tf.set_random_seed(2017)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "training_epochs = 20\n",
    "batch_size = 128\n",
    "\n",
    "for i in range(training_epochs + 1):\n",
    "    # 배치의 개수 미리 준비\n",
    "    n_of_batches = int(mnist.train.num_examples / batch_size)\n",
    "    \n",
    "    print(\"{}th epoch\".format(i))\n",
    "    for batch in range(n_of_batches):\n",
    "        X_batch, Y_batch = mnist.train.next_batch(batch_size)\n",
    "        # 학습 진행\n",
    "        sess.run(optimizer, feed_dict={X: X_batch, Y: Y_batch})\n",
    "        \n",
    "        if (batch % 25 == 0):\n",
    "            tr_a, loss = sess.run([accuracy, cost], feed_dict={X: X_batch, Y: Y_batch})\n",
    "            print(\"training loss: {:.4f} accuracy: {:.2f}%\".format(loss, tr_a * 100))\n",
    "\n",
    "print(\"Training Complete\")\n",
    "test_accuracy = sess.run(accuracy, feed_dict={X: mnist.test.images, Y: mnist.test.labels})\n",
    "print(\"Test Accuracy: {:.2f}%\".format(test_accuracy * 100))\n",
    "# print(sess.run([W[:, 0], b]))\n",
    "# sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 성능을 한 번 확인해 보자. 제대로 되고 있는걸까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(np.random.uniform(0, 9999, 1))\n",
    "n = 9719\n",
    "Predicted_distribution = sess.run(Y_prob, feed_dict={X: [mnist.test.images[n]]})\n",
    "Predicted_distribution = Predicted_distribution[0]\n",
    "pd_dict = {i: '%.2f' % prob for i, prob in enumerate(Predicted_distribution)}\n",
    "\n",
    "print(n)\n",
    "print(pd_dict)\n",
    "mnist_plot(n)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 좀 더 멋지게\n",
    "1. hyper parameter 중 - 변수 초기화 알고리즘 사용\n",
    "2. 그래프를 보기에 더 좋게 하려면 => name_scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Graph Clear & Make your Graph reproducible\n",
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(2017)\n",
    "\n",
    "# Hyper-Parameters & Option\n",
    "learning_rate = 0.01\n",
    "training_epochs = 20\n",
    "batch_size = 128\n",
    "\n",
    "# Input Layer, Real Y\n",
    "with tf.name_scope(\"Input_Layer\"):\n",
    "    X = tf.placeholder(dtype=tf.float32, shape=[None, 28 * 28], name='X_input')\n",
    "with tf.name_scope(\"Labels\"):\n",
    "    Y = tf.placeholder(dtype=tf.float32, shape=[None, 10], name='Y_input')\n",
    "\n",
    "# 1st Hidden Layer\n",
    "with tf.name_scope(\"Hidden_Layer_1\"):\n",
    "    W1 = tf.get_variable(name='Weight1', shape=[28 * 28, 512],\n",
    "                         initializer=tf.contrib.layers.xavier_initializer())\n",
    "    b1 = tf.Variable(tf.truncated_normal([512], mean=0, stddev=0.5), name='Bias1')\n",
    "    sum1 = tf.add(tf.matmul(X, W1), b1, name='sum1')\n",
    "    hidden_output1 = tf.nn.relu(sum1 ,name='Output1')\n",
    "\n",
    "# 2nd Hidden Layer\n",
    "with tf.name_scope(\"Hidden_Layer_2\"):\n",
    "    W2 = tf.get_variable(name='Weight2', shape=[512, 512],\n",
    "                         initializer=tf.contrib.layers.xavier_initializer())\n",
    "    b2 = tf.Variable(tf.truncated_normal([512], mean=0, stddev=0.5), name='Bias2')\n",
    "    sum2 = tf.add(tf.matmul(hidden_output1, W2), b2, name='sum2')\n",
    "    hidden_output2 = tf.nn.relu(sum2, name='Output2')\n",
    "\n",
    "# 3rd Hidden Layer\n",
    "with tf.name_scope(\"Hidden_Layer_3\"):\n",
    "    W3 = tf.get_variable(name='Weight3', shape=[512, 256],\n",
    "                         initializer=tf.contrib.layers.xavier_initializer())\n",
    "    b3 = tf.Variable(tf.truncated_normal([256], mean=0, stddev=0.5), name='Bias3')\n",
    "    sum3 = tf.add(tf.matmul(hidden_output2, W3), b3, name='sum3')\n",
    "    hidden_output3 = tf.nn.relu(sum3, name='Output3')\n",
    "    \n",
    "# 4nd Hidden Layer\n",
    "with tf.name_scope(\"Hidden_Layer_4\"):\n",
    "    W4 = tf.get_variable(name='Weight4', shape=[256, 128],\n",
    "                         initializer=tf.contrib.layers.xavier_initializer())\n",
    "    b4 = tf.Variable(tf.truncated_normal([128], mean=0, stddev=0.5), name='Bias4')\n",
    "    sum4 = tf.add(tf.matmul(hidden_output3, W4), b4, name='sum4')\n",
    "    hidden_output4 = tf.nn.relu(sum4, name='Output4')\n",
    "\n",
    "# Output Layer\n",
    "with tf.name_scope(\"Output_Layer\"):\n",
    "    Wo = tf.get_variable(name='Weight_output', shape=[128, 10],\n",
    "                         initializer=tf.contrib.layers.xavier_initializer())\n",
    "    bo = tf.Variable(tf.truncated_normal([10], mean=0, stddev=0.5), name='Bias_output')\n",
    "    logits = tf.add(tf.matmul(hidden_output4, Wo), bo, name='logit')\n",
    "    Y_prob = tf.nn.softmax(logits, name='Y_distribution_predicted')\n",
    "\n",
    "# Accuracy and cost\n",
    "with tf.name_scope(\"Accuracy_and_Cost\"):\n",
    "    n_of_correct = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1), name='Comparison')\n",
    "    accuracy = tf.reduce_mean(tf.cast(n_of_correct, tf.float32), name='Accuracy')\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y), name='Cross_entropy')\n",
    "\n",
    "# Optimizer\n",
    "with tf.name_scope(\"Optimizer\"):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "tf.set_random_seed(2017)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "training_epochs = 20\n",
    "batch_size = 128\n",
    "\n",
    "for i in range(training_epochs + 1):\n",
    "    # 배치의 개수 미리 준비\n",
    "    n_of_batches = int(fashion.train.num_examples / batch_size)\n",
    "    \n",
    "    print(\"{}th epoch\".format(i))\n",
    "    for batch in range(n_of_batches):\n",
    "        X_batch, Y_batch = fashion.train.next_batch(batch_size)\n",
    "        # 학습 진행\n",
    "        sess.run(optimizer, feed_dict={X: X_batch, Y: Y_batch})\n",
    "        \n",
    "        if (batch % 25 == 0):\n",
    "            tr_a, loss = sess.run([accuracy, cost], feed_dict={X: X_batch, Y: Y_batch})\n",
    "            print(\"training loss: {:.4f} accuracy: {:.2f}%\".format(loss, tr_a * 100))\n",
    "            \n",
    "print(\"Training Complete\")        \n",
    "test_accuracy = sess.run(accuracy, feed_dict={X: mnist.test.images, Y: mnist.test.labels})\n",
    "print(\"Test Accuracy: {:.2f}%\".format(test_accuracy * 100))\n",
    "# print(sess.run([W[:, 0], b]))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tbij import show_graph\n",
    "show_graph(tf.get_default_graph().as_graph_def())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (CHALLENGE!) MNIST is too easy, huh?!\n",
    "\n",
    "## Here Comes the 'FASHION MNIST'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "77420740-c7d1-42dc-8cbf-f131e6ac7001"
    }
   },
   "source": [
    "### 00. 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from tbij import show_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01.  모든 전처리들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/'\n",
    "fashion = input_data.read_data_sets('./Fashion_data/',\n",
    "                                    source_url=url, \n",
    "                                    one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Fashion mnist 시각화 함수\n",
    "'''\n",
    "def fashion_plot(i):\n",
    "    pixels = fashion.test.images[i].reshape((28, 28))\n",
    "    a = fashion.test.labels.tolist()\n",
    "    plt.title('Label : {}'.format(a[i].index(1)))\n",
    "    plt.imshow(pixels, cmap='gray')\n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Label\t| Description |\n",
    "|:------|------:|\n",
    "|0|T-shirt/top|\n",
    "|1|\tTrouser|\n",
    "|2|\tPullover|\n",
    "|3|\tDress|\n",
    "|4|\tCoat|\n",
    "|5|\tSandal|\n",
    "|6|\tShirt|\n",
    "|7|\tSneaker|\n",
    "|8|\tBag|\n",
    "|9|\tAnkle boot|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "반복실행해보자\n",
    "'''\n",
    "fashion_plot(np.random.randint(0, high=9999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "트레이닝 데이터로 활용할 55000개 이미지, 테스트용 10000개 이미지\n",
    "28*28 사이즈의 이미지가 그냥 주욱 784칸 짜리 어레이에 담겨있다.\n",
    "레이블은 이미 one-hot encoding이 되어 있다.\n",
    "'''\n",
    "print(fashion.train.images.shape, fashion.train.labels.shape)\n",
    "print(fashion.test.images.shape, fashion.test.labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######################################################\n",
    "#                    코딩하시면 됩니다!\n",
    "######################################################\n",
    "\n",
    "# Graph Clear & Make your Graph reproducible\n",
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(2017)\n",
    "\n",
    "# Hyper-Parameters & Option\n",
    "learning_rate = 0.01\n",
    "training_epochs = 10\n",
    "batch_size = 128\n",
    "\n",
    "# Input Layer, Real Y\n",
    "X = tf.placeholder(dtype=tf.float32, shape=[None, 784])\n",
    "Y = tf.placeholder(dtype=tf.float32, shape=[None, 10])\n",
    "\n",
    "# 1nd Hidden Layer\n",
    "W1 = tf.Variable(tf.random_normal([784, 512]))\n",
    "b1 = tf.Variable(tf.random_normal([512]))\n",
    "sum1 = tf.add(tf.matmul(X, W1), b1)\n",
    "hidden_output1 = tf.nn.relu(sum1)\n",
    "\n",
    "# 2nd Hidden Layer\n",
    "W2 = tf.Variable(tf.random_normal([512, 512]))\n",
    "b2 = tf.Variable(tf.random_normal([512]))\n",
    "sum2 = tf.add(tf.matmul(hidden_output1, W2), b2)\n",
    "hidden_output2 = tf.nn.relu(sum2)\n",
    "\n",
    "# 3rd Hidden Layer\n",
    "W3 = tf.Variable(tf.random_normal([512, 256]))\n",
    "b3 = tf.Variable(tf.random_normal([256]))\n",
    "sum3 = tf.add(tf.matmul(hidden_output2, W3), b3)\n",
    "hidden_output3 = tf.nn.relu(sum3)\n",
    "\n",
    "# 4nd Hidden Layer\n",
    "W4 = tf.Variable(tf.random_normal([256, 256]))\n",
    "b4 = tf.Variable(tf.random_normal([256]))\n",
    "sum4 = tf.add(tf.matmul(hidden_output3, W4), b4)\n",
    "hidden_output4 = tf.nn.relu(sum4)\n",
    "\n",
    "# Output Layer\n",
    "Wo = tf.Variable(tf.random_normal([512, 10]))\n",
    "bo = tf.Variable(tf.random_normal([10]))\n",
    "logits = tf.add(tf.matmul(hidden_output2, Wo), bo)\n",
    "Y_prob = tf.nn.softmax(logits, name='Y_distribution_predicted')\n",
    "\n",
    "# Accuracy and cost\n",
    "with tf.name_scope(\"Accuracy_and_Cost\"):\n",
    "    n_of_correct = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1), name='Comparison')\n",
    "    accuracy = tf.reduce_mean(tf.cast(n_of_correct, tf.float32))\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y), \n",
    "                          name='Cross_entropy')\n",
    "\n",
    "# Optimizer\n",
    "with tf.name_scope(\"Optimizer\"):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "tf.set_random_seed(2017)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "training_epochs = 20\n",
    "batch_size = 100\n",
    "\n",
    "for i in range(training_epochs + 1):\n",
    "    # 배치의 개수 미리 준비\n",
    "    n_of_batches = int(fashion.train.num_examples / batch_size)\n",
    "    \n",
    "    print(\"{}th epoch\".format(i))\n",
    "    for batch in range(n_of_batches):\n",
    "        X_batch, Y_batch = fashion.train.next_batch(batch_size)\n",
    "        # 학습 진행\n",
    "        sess.run(optimizer, feed_dict={X: X_batch, Y: Y_batch})\n",
    "        \n",
    "        if (batch % 25 == 0):\n",
    "            tr_a, loss = sess.run([accuracy, cost], feed_dict={X: X_batch, Y: Y_batch})\n",
    "            print(\"training loss: {:.4f} accuracy: {:.2f}%\".format(loss, tr_a * 100))\n",
    "\n",
    "print(\"Training Complete\")        \n",
    "test_accuracy = sess.run(accuracy, feed_dict={X: fashion.test.images, Y: fashion.test.labels})\n",
    "print(\"Test Accuracy: {:.2f}%\".format(test_accuracy * 100))\n",
    "# print(sess.run([W[:, 0], b]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "show_graph(tf.get_default_graph().as_graph_def())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = int(np.random.uniform(0, 9999, 1))\n",
    "Predicted_distribution = sess.run(Y_prob, feed_dict={X: [fashion.test.images[n]]})\n",
    "Predicted_distribution = Predicted_distribution[0]\n",
    "\n",
    "labels_list = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankleboot']\n",
    "pd_dict = {str(i) + \": \" + labels_list[i]: '%.2f' % prob for i, prob in enumerate(Predicted_distribution)}\n",
    "\n",
    "print(n)\n",
    "print(pd_dict)\n",
    "fashion_plot(n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "nbpresent": {
   "slides": {
    "06673961-d8a5-4267-a63d-f313583104d9": {
     "id": "06673961-d8a5-4267-a63d-f313583104d9",
     "prev": "0879f191-9570-41d0-8172-779e645958bf",
     "regions": {
      "c4b181e9-2fef-4c54-a02d-add6a6973d29": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "85cfbf31-402d-4db2-8b14-0d0c0d847f8b",
        "part": "whole"
       },
       "id": "c4b181e9-2fef-4c54-a02d-add6a6973d29"
      }
     }
    },
    "0879f191-9570-41d0-8172-779e645958bf": {
     "id": "0879f191-9570-41d0-8172-779e645958bf",
     "prev": "67db25c5-f042-401f-8d2a-56ba736d31ae",
     "regions": {
      "4df75cd2-c637-493e-a7cf-5f96fb3013ca": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "daf8cfb3-efc8-4e87-b318-e5ad4c12f9b7",
        "part": "whole"
       },
       "id": "4df75cd2-c637-493e-a7cf-5f96fb3013ca"
      }
     }
    },
    "135b3672-2ba5-4f92-bdc7-4113351248a2": {
     "id": "135b3672-2ba5-4f92-bdc7-4113351248a2",
     "prev": "53b495c0-f73a-4af8-90a9-06052a15578c",
     "regions": {
      "29d2786a-e00f-4936-8f88-98d140ceb69d": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "ae941080-9b54-48d0-9c2e-d789737ca6a3",
        "part": "whole"
       },
       "id": "29d2786a-e00f-4936-8f88-98d140ceb69d"
      }
     }
    },
    "234a438e-9bbd-4d7c-aa4d-60a6ad360cad": {
     "id": "234a438e-9bbd-4d7c-aa4d-60a6ad360cad",
     "prev": "85cdfd47-b188-4127-b6ce-f2d6269764ca",
     "regions": {
      "44c764a2-1cf0-4fc0-91cb-0cb9bcefb745": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "dfdb1509-35cf-46ef-8552-f6b07ed1fbaf",
        "part": "whole"
       },
       "id": "44c764a2-1cf0-4fc0-91cb-0cb9bcefb745"
      }
     }
    },
    "338a1c9f-d631-4cd8-9830-35c4b298ee7d": {
     "id": "338a1c9f-d631-4cd8-9830-35c4b298ee7d",
     "prev": "f609d9b0-5a29-4ccc-84bf-e74355ab7eff",
     "regions": {
      "cd095279-4007-4e90-b96e-0b95b9ec3a3d": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "b5521ec6-6f3a-4b09-ab8e-955e09c040c2",
        "part": "whole"
       },
       "id": "cd095279-4007-4e90-b96e-0b95b9ec3a3d"
      }
     }
    },
    "53b495c0-f73a-4af8-90a9-06052a15578c": {
     "id": "53b495c0-f73a-4af8-90a9-06052a15578c",
     "prev": "be1c5d87-98b8-4a00-8fee-ab6aa9209fa8",
     "regions": {
      "ae2aebd0-8691-47f8-8aab-528a9c1ce2bf": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "41a29509-236f-4951-a9d2-6c2cf4963c6b",
        "part": "whole"
       },
       "id": "ae2aebd0-8691-47f8-8aab-528a9c1ce2bf"
      }
     }
    },
    "579d08fd-aae6-4977-a954-3bfed185e258": {
     "id": "579d08fd-aae6-4977-a954-3bfed185e258",
     "prev": "338a1c9f-d631-4cd8-9830-35c4b298ee7d",
     "regions": {
      "12149eb4-94d4-40e8-8ed1-5b01b3dc17ab": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "d1c43f06-e63a-4006-84fe-a80d43007720",
        "part": "whole"
       },
       "id": "12149eb4-94d4-40e8-8ed1-5b01b3dc17ab"
      }
     }
    },
    "67db25c5-f042-401f-8d2a-56ba736d31ae": {
     "id": "67db25c5-f042-401f-8d2a-56ba736d31ae",
     "prev": "579d08fd-aae6-4977-a954-3bfed185e258",
     "regions": {
      "8a7cf766-88b1-4512-ba59-c0907d84e812": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "6d01f784-fa77-43fc-a1de-5dca9733fe37",
        "part": "whole"
       },
       "id": "8a7cf766-88b1-4512-ba59-c0907d84e812"
      }
     }
    },
    "6864bc82-39ed-4597-9643-1f9eaebaa4ad": {
     "id": "6864bc82-39ed-4597-9643-1f9eaebaa4ad",
     "prev": null,
     "regions": {
      "458e5b71-90c5-4b8b-946f-3dbd0acabdd0": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "324c3256-4054-4685-a71c-ae0fe87670c2",
        "part": "whole"
       },
       "id": "458e5b71-90c5-4b8b-946f-3dbd0acabdd0"
      }
     }
    },
    "85cdfd47-b188-4127-b6ce-f2d6269764ca": {
     "id": "85cdfd47-b188-4127-b6ce-f2d6269764ca",
     "prev": "135b3672-2ba5-4f92-bdc7-4113351248a2",
     "regions": {
      "660896c7-2008-4690-a456-0f728323a4e9": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "ff5d24f2-939f-4007-9892-f241c94b9e6f",
        "part": "whole"
       },
       "id": "660896c7-2008-4690-a456-0f728323a4e9"
      }
     }
    },
    "be1c5d87-98b8-4a00-8fee-ab6aa9209fa8": {
     "id": "be1c5d87-98b8-4a00-8fee-ab6aa9209fa8",
     "prev": "6864bc82-39ed-4597-9643-1f9eaebaa4ad",
     "regions": {
      "02737d00-d567-4b1e-b981-39dc866fb994": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "77420740-c7d1-42dc-8cbf-f131e6ac7001",
        "part": "whole"
       },
       "id": "02737d00-d567-4b1e-b981-39dc866fb994"
      }
     }
    },
    "f609d9b0-5a29-4ccc-84bf-e74355ab7eff": {
     "id": "f609d9b0-5a29-4ccc-84bf-e74355ab7eff",
     "prev": "234a438e-9bbd-4d7c-aa4d-60a6ad360cad",
     "regions": {
      "aec5f004-bdc5-449c-80b3-52d3a1ae4596": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "439e3e1e-bdee-49a7-9a18-11f87ded9522",
        "part": "whole"
       },
       "id": "aec5f004-bdc5-449c-80b3-52d3a1ae4596"
      }
     }
    }
   },
   "themes": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
